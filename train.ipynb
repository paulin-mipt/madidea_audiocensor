{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed training examples\n",
    "X = np.load(\"./ml/train/X.npy\")\n",
    "Y = np.load(\"./ml/train/Y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 11998, 101), (1000, 2996, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed training examples\n",
    "X_test = np.load(\"./ml/test/X.npy\")\n",
    "Y_test = np.load(\"./ml/test/Y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 11998, 101), (100, 2996, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D\n",
    "from keras.layers import GRU, Bidirectional, BatchNormalization, Reshape\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: model\n",
    "\n",
    "def model(input_shape):\n",
    "    \"\"\"\n",
    "    Function creating the model's graph in Keras.\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    X_input = Input(shape = input_shape)\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Step 1: CONV layer (≈4 lines)\n",
    "    X = Conv1D(196, kernel_size=15, strides=4)(X_input)                                 # CONV1D\n",
    "    X = BatchNormalization()(X)                                 # Batch normalization\n",
    "    X = Activation('relu')(X)                                 # ReLu activation\n",
    "    X = Dropout(0.8)(X)                                 # dropout (use 0.8)\n",
    "\n",
    "    # Step 2: First GRU Layer (≈4 lines)\n",
    "    X = GRU(units = 128, return_sequences = True)(X) # GRU (use 128 units and return the sequences)\n",
    "    X = Dropout(0.8)(X)                                 # dropout (use 0.8)\n",
    "    X = BatchNormalization()(X)                                 # Batch normalization\n",
    "    \n",
    "    # Step 3: Second GRU Layer (≈4 lines)\n",
    "    X = GRU(units = 128, return_sequences = True)(X)   # GRU (use 128 units and return the sequences)\n",
    "    X = Dropout(0.8)(X)                                 # dropout (use 0.8)\n",
    "    X = BatchNormalization()(X)                                  # Batch normalization\n",
    "    X = Dropout(0.8)(X)                                  # dropout (use 0.8)\n",
    "    \n",
    "    # Step 4: Time-distributed dense layer (≈1 line)\n",
    "    X = TimeDistributed(Dense(1, activation = \"sigmoid\"))(X) # time distributed  (sigmoid)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    \n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tx = 11998 # The number of time steps input to the model from the spectrogram\n",
    "n_freq = 101 # Number of frequencies input to the model at each time step of the spectrogram\n",
    "Ty = 2996 # The number of time steps in the output of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model(input_shape = (Tx, n_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 11998, 101)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 2996, 196)         297136    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 2996, 196)         784       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 2996, 196)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2996, 196)         0         \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 2996, 128)         124800    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2996, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 2996, 128)         512       \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 2996, 128)         98688     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2996, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 2996, 128)         512       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 2996, 128)         0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 2996, 1)           129       \n",
      "=================================================================\n",
      "Total params: 522,561\n",
      "Trainable params: 521,657\n",
      "Non-trainable params: 904\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d5c59fc45f92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(X, Y, batch_size = 50, epochs=100, \n\u001b[1;32m      2\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m           )\n",
      "\u001b[0;32m~/workspace/shad/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/workspace/shad/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/shad/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/shad/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/shad/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X, Y, batch_size = 50, epochs=100, \n",
    "              callbacks=[EarlyStopping()],\n",
    "              validation_data=(X_test, Y_test)\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_1 to have shape (5511, 101) but got array with shape (11998, 101)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e27ed1bf1282>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test set accuracy = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/shad/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/shad/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/shad/lib/python3.5/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    135\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_1 to have shape (5511, 101) but got array with shape (11998, 101)"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, Y_test)\n",
    "print(\"Test set accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_triggerword(filename):\n",
    "    plt.subplot(2, 1, 1)\n",
    "\n",
    "    x, data, rate, times = graph_spectrogram(filename)\n",
    "    print(get_wav_info(filename))\n",
    "    # the spectogram outputs (freqs, Tx) and we want (Tx, freqs) to input into the model\n",
    "    x  = x.swapaxes(0,1)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    print(len(x), len(x[0]))\n",
    "    print(x[0])\n",
    "    predictions = model.predict(x)\n",
    "    \n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(predictions[0,:,0])\n",
    "    print(predictions[0,:,0])\n",
    "    plt.ylabel('probability')\n",
    "    plt.show()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ml/generated/train800.wav\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'graph_spectrogram' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-0e3be0719259>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_triggerword\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-7d2bb114e158>\u001b[0m in \u001b[0;36mdetect_triggerword\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_spectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_wav_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# the spectogram outputs (freqs, Tx) and we want (Tx, freqs) to input into the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'graph_spectrogram' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "filename_t = \"./ml/generated/train{0}.wav\"\n",
    "i = 800\n",
    "while True:\n",
    "    try:\n",
    "        filename = filename_t.format(i)\n",
    "        print(filename)\n",
    "        prediction = detect_triggerword(filename)\n",
    "        break\n",
    "    except ValueError:\n",
    "        i += 1\n",
    "        continue\n",
    "\n",
    "IPython.display.Audio(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('1_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
